[2026-01-25 16:46:04,838 I 2420792 2420792] core_worker_process.cc:777: Constructing CoreWorkerProcess. pid: 2420792
[2026-01-25 16:46:04,842 I 2420792 2420792] event.cc:499: Ray Event initialized for CORE_WORKER
[2026-01-25 16:46:04,842 I 2420792 2420792] event.cc:499: Ray Event initialized for EXPORT_TASK
[2026-01-25 16:46:04,842 I 2420792 2420792] event.cc:332: Set ray event level to warning
[2026-01-25 16:46:04,842 I 2420792 2420792] event_aggregator_client.h:50: Initiating the local event aggregator client with port: 64258
[2026-01-25 16:46:04,843 I 2420792 2420792] grpc_server.cc:143: worker server started, listening on port 40893.
[2026-01-25 16:46:04,852 I 2420792 2420792] core_worker_process.cc:262: Initializing worker at address: 172.28.6.5:40893 worker_id=f83547b2d6e88ce38f8c6661e9f2ce1a575a2c96f647a6f47f772106 node_id=4f226b4fe4b290f4d252817708466ab16d04df7faef9706c068db3a2
[2026-01-25 16:46:04,853 I 2420792 2420792] task_event_buffer.cc:480: Reporting task events to GCS every 1000ms.
[2026-01-25 16:46:04,854 I 2420792 2420792] core_worker.cc:515: Adjusted worker niceness to 15
[2026-01-25 16:46:04,854 I 2420792 2420792] metrics_agent_client.cc:45: Initializing exporter ...
[2026-01-25 16:46:04,854 I 2420792 2420829] core_worker.cc:455: Event stats:


Global stats: 12 total (10 active)
Queueing time: mean = 0.00ms, max = 0.04ms, min = 0.02ms, total = 0.05ms
Execution time:  mean = 0.00ms, total = 0.05ms
Event stats:
	PeriodicalRunner.RunFnPeriodically - 7 total (5 active, 1 running), Execution time: mean = 0.01ms, total = 0.05ms, Queueing time: mean = 0.01ms, max = 0.04ms, min = 0.02ms, total = 0.05ms
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
	Publisher.CheckDeadSubscribers - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
	CoreWorker.ExitIfParentRayletDies - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms

-----------------
Task execution event stats:

Global stats: 0 total (0 active)
Queueing time: mean = -nanms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
Execution time:  mean = -nanms, total = 0.00ms
Event stats:

-----------------
Task Event stats:

IO Service Stats:

Global stats: 4 total (1 active)
Queueing time: mean = 0.01ms, max = 0.02ms, min = 0.01ms, total = 0.02ms
Execution time:  mean = 0.21ms, total = 0.83ms
Event stats:
	CoreWorker.deadline_timer.flush_task_events - 1 total (1 active), Execution time: mean = 0.00ms, total = 0.00ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
	PeriodicalRunner.RunFnPeriodically - 1 total (0 active), Execution time: mean = 0.18ms, total = 0.18ms, Queueing time: mean = 0.01ms, max = 0.01ms, min = 0.01ms, total = 0.01ms
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData.OnReplyReceived - 1 total (0 active), Execution time: mean = 0.02ms, total = 0.02ms, Queueing time: mean = 0.02ms, max = 0.02ms, min = 0.02ms, total = 0.02ms
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData - 1 total (0 active), Execution time: mean = 0.63ms, total = 0.63ms, Queueing time: mean = 0.00ms, max = -0.00ms, min = 9223372036854.78ms, total = 0.00ms
Other Stats:
	gcs_grpc_in_progress:0
	event_aggregator_grpc_in_progress:0
	current number of task status events in buffer: 0
	current number of profile events in buffer: 0
	current number of dropped task attempts tracked: 0
	total task events sent: 0 MiB
	total number of task attempts sent: 0
	total number of task attempts dropped reported: 0
	total number of sent failure: 0
	num status task events dropped: 0
	num profile task events dropped: 0
	num ray task events reported to aggregator: 0
	num ray task events failed to report to aggregator: 0
	num of task attempts dropped reported to aggregator: 0
	num of failed requests to aggregator: 0

[2026-01-25 16:46:04,857 I 2420792 2420829] metrics_agent_client.cc:59: Exporter initialized.
[2026-01-25 16:46:04,857 I 2420792 2420829] accessor.cc:433: Received address and liveness notification for node, IsAlive = 1 node_id=4f226b4fe4b290f4d252817708466ab16d04df7faef9706c068db3a2
[2026-01-25 16:46:04,857 I 2420792 2420829] normal_task_submitter.cc:840: Number of alive nodes:1
[2026-01-25 16:46:04,857 I 2420792 2420792] actor_task_submitter.cc:75: Set actor max pending calls to -1 actor_id=ba9e320e8763c5ec2afe7ee501000000
[2026-01-25 16:46:04,857 I 2420792 2420792] core_worker.cc:2904: Creating actor actor_id=ba9e320e8763c5ec2afe7ee501000000
[2026-01-25 16:46:10,703 I 2420792 2420792] actor_task_submitter.cc:75: Set actor max pending calls to 0 actor_id=c52f86fb1dd5079f0934e02f01000000
[2026-01-25 16:46:10,734 I 2420792 2420829] actor_manager.cc:236: received notification on actor, state: ALIVE, ip address: 172.28.6.5, port: 34233, num_restarts: 0, death context type=CONTEXT_NOT_SET actor_id=c52f86fb1dd5079f0934e02f01000000 worker_id=3d3c1c37aeda59d69a21bff9ba043b0feef79de80728a26e06895538 node_id=4f226b4fe4b290f4d252817708466ab16d04df7faef9706c068db3a2
[2026-01-25 16:46:10,898 I 2420792 2420792] task_receiver.cc:142: Actor creation task finished, task_id: ffffffffffffffffba9e320e8763c5ec2afe7ee501000000, actor_id: ba9e320e8763c5ec2afe7ee501000000, actor_repr_name: 
[2026-01-25 16:46:52,839 I 2420792 2420829] actor_manager.cc:236: received notification on actor, state: DEAD, ip address: 172.28.6.5, port: 34233, num_restarts: 0, death context type=ActorDiedErrorContext actor_id=c52f86fb1dd5079f0934e02f01000000 worker_id=3d3c1c37aeda59d69a21bff9ba043b0feef79de80728a26e06895538 node_id=4f226b4fe4b290f4d252817708466ab16d04df7faef9706c068db3a2
[2026-01-25 16:46:52,840 I 2420792 2420829] actor_task_submitter.cc:424: Failing pending tasks for actor because the actor is already dead. actor_id=c52f86fb1dd5079f0934e02f01000000
[2026-01-25 16:46:52,840 I 2420792 2420792] core_worker_shutdown_executor.cc:94: Executing worker exit: SYSTEM_ERROR - Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM. (timeout: -1ms)
[2026-01-25 16:46:52,840 I 2420792 2420792] core_worker_shutdown_executor.cc:128: Wait for currently executing tasks in the underlying thread pools to finish.
[2026-01-25 16:46:52,840 W 2420792 2420792] core_worker_shutdown_executor.cc:138: Failed to notify Raylet. The raylet may have already shut down or the connection was lost.
[2026-01-25 16:46:52,840 I 2420792 2420792] core_worker_shutdown_executor.cc:170: Not draining reference counter since this is an actor worker.
[2026-01-25 16:46:52,859 I 2420792 2420792] core_worker_shutdown_executor.cc:217: Try killing all child processes of this worker as it exits. Child process pids: 
[2026-01-25 16:46:52,860 I 2420792 2420792] core_worker_shutdown_executor.cc:262: Sending disconnect message to the local raylet.
[2026-01-25 16:46:52,860 I 2420792 2420792] raylet_ipc_client.cc:135: RayletIpcClient::Disconnect, exit_type=SYSTEM_ERROR, exit_detail=Worker exits unexpectedly by a signal. SystemExit is raised (sys.exit is called). Exit code: 1. The process receives a SIGTERM., has creation_task_exception_pb_bytes=0
[2026-01-25 16:46:52,860 W 2420792 2420792] core_worker_shutdown_executor.cc:281: Failed to disconnect from the local raylet: IOError: Broken pipe
[2026-01-25 16:46:52,979 I 2420792 2420792] task_event_buffer.cc:491: Shutting down TaskEventBuffer.
[2026-01-25 16:46:52,979 I 2420792 2420849] task_event_buffer.cc:459: Task event buffer io service stopped.
[2026-01-25 16:46:52,979 I 2420792 2420792] core_worker_shutdown_executor.cc:54: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service.
[2026-01-25 16:46:52,979 I 2420792 2420829] core_worker_process.cc:195: Core worker main io service stopped.
[2026-01-25 16:46:52,983 I 2420792 2420792] core_worker_shutdown_executor.cc:72: Disconnecting a GCS client.
[2026-01-25 16:46:52,983 I 2420792 2420792] core_worker_shutdown_executor.cc:79: Core worker ready to be deallocated.
[2026-01-25 16:46:52,983 I 2420792 2420792] core_worker_process.cc:955: Task execution loop terminated. Removing the global worker.
[2026-01-25 16:46:52,983 I 2420792 2420792] core_worker.cc:539: Core worker is destructed
[2026-01-25 16:46:52,983 I 2420792 2420792] task_event_buffer.cc:491: Shutting down TaskEventBuffer.
[2026-01-25 16:46:53,085 I 2420792 2420792] core_worker_process.cc:851: Destructing CoreWorkerProcessImpl. pid: 2420792
[2026-01-25 16:46:53,087 W 2420792 2421923] open_telemetry_metric_recorder.cc:66: Failed to export metrics to the metrics agent. Result: 1
[2026-01-25 16:46:53,087 I 2420792 2420792] stats.h:149: Stats module has shutdown.
